{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"IRIS integrate","text":"<p>Predict if a person may be impaired due to substance use.</p> <p>IRIS integrate performs a scan to predict if a person may be impaired due to substance use. The user tracks a dot with their eyes while the framework records device motion and facial features. The anonymized data is fed into a machine learning model hosted on servers run by Sightic Analytics to generate a prediction.</p> <p>Important</p> <p>This framework is not a medical device and should not be used to diagnose or treat any medical condition.</p>"},{"location":"#topics","title":"Topics","text":""},{"location":"#essentials","title":"Essentials","text":"<ul> <li>Phases</li> <li>API key</li> <li>Integrating with your app</li> </ul>"},{"location":"api-key/","title":"API Key","text":"<p>IRIS integrate requires an API key in order to provide a result to the host application. Please get in touch with Sightic Analytics to retrieve a key.</p> <p>The API key is provided to the performInference(apiKey: String) function of the SighticRecording object.</p>"},{"location":"integrating/","title":"Integrating with Your App","text":""},{"location":"integrating/#usage","title":"Usage","text":"<p>To use IRIS integrate in your project, follow these steps</p> <ol> <li> <p>Add IRIS integrate dependency to your app module build.gradle. Newest version can be found on MavenCentral</p> KotlinGroovy <pre><code>implementation(\"com.sightic:irisintegrate:(insert version here)\")\n</code></pre> <pre><code>implementation \"com.sightic:irisintegrate:(insert version here)\"\n</code></pre> </li> <li> <p>IRIS integrate requires minSdk of 30. If you app has a lower min sdk. Consider bump version or check the section about using IRIS integrate with a lower minSdk than 30 </p> </li> <li> <p>Add these lines to your manifest file</p> AndroidManifest.xml<pre><code>&lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:tools=\"http://schemas.android.com/tools\"&gt;\n    &lt;uses-feature android:name=\"android.hardware.camera\" android:required=\"false\" /&gt;\n    &lt;uses-permission android:name=\"android.permission.CAMERA\" /&gt;\n    &lt;uses-permission android:name=\"android.permission.HIGH_SAMPLING_RATE_SENSORS\"\n        tools:ignore=\"HighSamplingRate\" /&gt;\n    &lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;\n\n    &lt;application \n        android:largeHeap=\"true\" &gt; &lt;!-- Add this line to your application block --&gt;\n    &lt;/application&gt;\n\n&lt;!-- Rest of your manifest code --&gt;\n\n&lt;/manifest&gt;\n</code></pre> </li> <li> <p>Add SighticView to your app. You must let it occupy the whole screen.</p> </li> <li>The app user aligns and then performs the scan by following the dot with their eyes.</li> <li>If the scan was successful a SighticRecording object is returned.</li> <li>Call the performInference(apiKey: String) function on the recording.</li> <li>Wait for result from the Sightic Analytics server.</li> <li>A SighticInference object is returned which contains the scan result.</li> <li>AlignmentError represent errors that occur during the scan. SighticError represent errors that occur during the analysis of a recording.</li> </ol>"},{"location":"integrating/#quickstart-app","title":"QuickStart app","text":"<p>Sightic Analytics provides a QuickStart app that shows how to use the framework.</p>"},{"location":"integrating/#gradle","title":"Gradle","text":"<p>Add IRIS integrate as a gradle dependency.</p>"},{"location":"integrating/#camera-access","title":"Camera access","text":"<p>IRIS integrate need access to the device's camera, thus you must add camera permission and feature in your manifest file. Requesting runtime permissions will be taken care of inside SighticView</p>"},{"location":"integrating/#sightic-view","title":"Sightic view","text":"<ol> <li>Add SighticView  to your app. You must let the view occupy the whole screen.</li> <li>Provide a completion lambda that accepts a SighticResult of either SighticRecording  or a SighticError.</li> </ol>"},{"location":"integrating/#alignment","title":"Alignment","text":"<p>The alignment view helps the app user position their face in front of the screen. The viewfinder turns green when alignment is correct followed by a countdown before the scan starts.</p> <p></p>"},{"location":"integrating/#scan","title":"Scan","text":"<p>A black moving dot is shown during the scan. The app user follows the dot with their eyes while keeping the phone still. The framework records the face of the user while the dot is shown.</p> <p></p> <p>The alignment view reappears if the user misaligns while doing the scan, for example by moving the device too close. A hint is provided on how to fix the alignment. The scan restarts from the beginning after the user has made corrections. We call this soft reset. If the user triggers soft reset more than three times the control is returned back to the host app with a AlignmentError.</p> <p></p>"},{"location":"integrating/#recording","title":"Recording","text":"<ol> <li>SighticView triggers the completion handler back to the app to indicate that the recording has finished.</li> <li>The app receives a SighticResult of either SighticRecording or SighticError.</li> <li>SighticError is a sealed class with errors that can occur while doing the scan. One example is InterruptedError which is triggered if the user moves the app into the background.</li> </ol>"},{"location":"integrating/#inference-request","title":"Inference request","text":"<ol> <li>The host app calls performInference(apiKey: String) on the SighticRecording object to send the recorded data to the Sightic Analytics server for analysis.</li> <li>The app receives a SighticInference object with the scan result or a SighticError if an error occurs. We get a InferenceError if we for example provide an invalid API key or a NoNetworkConnection if there is no internet connection.</li> <li>SighticInference contains hasImpairment that indicates whether the scan subject is possibly impaired.</li> </ol>"},{"location":"integrating/#using-iris-integrate-with-a-lower-minsdk-than-30","title":"Using IRIS integrate with a lower minSdk than 30","text":"<p>If your app has a lower minSdk than 30 you need some additional setup to get it to work</p> <p>Add this to you manifest file AndroidManifest.xml<pre><code>    &lt;uses-sdk\n        tools:overrideLibrary=\"com.sightic.irisintegrate\"\n        /&gt;\n</code></pre></p> <p>When you add SighticView you need to check if users device is running on at least minSdk 30</p> <pre><code>if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.R) {\n    SighticView { }\n} else {\n    // Do something else\n}\n</code></pre>"},{"location":"phases/","title":"Phases","text":"<p>A description of the IRIS integrate user interface flow.</p> <p>When adding IRIS integrate to your app, the user experience has two parts:</p> <ul> <li>The views implemented by your app, also referred to as the \"host app\", to introduce the scan and display the results. </li> <li>The IRIS integrate flow, which is entirely handled by SighticView.</li> </ul> <pre><code>---\nconfig:\n  theme: base\n  themeVariables:\n    actorLineColor: \"#444444\"\n---\nsequenceDiagram\n  participant A as Host app\n  participant B as SighticView\n  participant C as Sightic Analytics server\n  Note over B: Handles the test flow\n  A -&gt;&gt; B: Presents\n  alt Success\n    B --&gt;&gt; A: SighticRecording\n  else Failure\n    B --&gt;&gt; A: SighticError\n  end\n  A -&gt;&gt; C : performInference()\n    alt Success\n    C --&gt;&gt; A: SighticInference\n  else Failure\n    C --&gt;&gt; A: SighticError\n  end</code></pre> <p>An example implementation is available in the IRIS integrate Quickstart project.</p>"},{"location":"phases/#alignment","title":"Alignment","text":"<p>The alignment view helps the user position their face correctly in front of the device.</p> <p>There is also a button to cancel the alignment and return control to the host app.</p>"},{"location":"phases/#scan","title":"Scan","text":"<p>A moving dot is shown to the app user during the scan. The user should follow the dot with their eyes.</p> <p>The scan will return to the alignment view if the user misaligns while doing the scan, for example by moving the device too far away from their face. A hint is provided on how to fix the misalignment. The scan restarts from the beginning when the user is correctly positioned. If the user fails to keep sufficiently aligned during the scan three times, control is returned back to the host app with a AlignmentError result.</p>"},{"location":"phases/#analysis","title":"Analysis","text":"<p>The SighticView completion callback provides the host app with the recorded data as a SighticRecording object when the user has completed the scan.</p> <p>The host app sends the recorded data to the Sightic Analytics server for analysis by calling SighticRecording/performInference(). The data sent to the server contains device motions and features extracted from the face of the app user. The data does not contain a video stream that can be used to identify the user.</p> <p>The app receives a SighticInference with the scan result, or a SighticError if an error occurs.</p>"}]}